{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636a922a-8359-4a88-98a8-5258aa092fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 15:12:27.122741: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-22 15:12:27.154158: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 15:12:27.154236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 15:12:27.155117: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 15:12:27.159896: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-22 15:12:27.160420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-22 15:12:27.711179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326a30a2-08f8-45ad-a90b-c2371622db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets from './data_sets'\n",
    "data_path = './data_sets'\n",
    "input_datasets = []\n",
    "output_datasets = []\n",
    "\n",
    "# Assuming your files are named input_data_1.csv, input_data_2.csv, ..., output_data_1.csv, output_data_2.csv, ...\n",
    "for i in range(1, 301):\n",
    "    input_file = os.path.join(data_path, f'input_data_{i:04d}.csv')\n",
    "    output_file = os.path.join(data_path, f'output_data_{i:04d}.csv')\n",
    "\n",
    "    # Load data using pandas\n",
    "    # input_data = pd.read_csv(input_file, delimiter=',', dtype=int).values\n",
    "    # output_data = pd.read_csv(output_file, delimiter=','dtype=int).values\n",
    "    input_data = np.genfromtxt(input_file, delimiter=',', dtype=int)\n",
    "    output_data = np.genfromtxt(output_file, delimiter=',', dtype=int)\n",
    "\n",
    "    input_datasets.append(input_data)\n",
    "    output_datasets.append(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead893c9-8ad5-4dcd-82e0-4da08db3f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to NumPy arrays\n",
    "X = np.array(input_datasets, dtype=float)\n",
    "y = np.array(output_datasets, dtype=float)\n",
    "\n",
    "# Reshape y to be a 2D array\n",
    "# y = y.reshape(-1, 1)\n",
    "\n",
    "# Normalize the input data\n",
    "# scaler_X = StandardScaler()\n",
    "# X = scaler_X.fit_transform(X)\n",
    "scaler_X = 45.0\n",
    "X = X/scaler_X\n",
    "\n",
    "# Normalize the output data\n",
    "# scaler_y = StandardScaler()\n",
    "# y = scaler_y.fit_transform(y)\n",
    "scaler_y = 45.0\n",
    "y = y/scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad57473-e2f8-4a06-b2e0-f7a19db50f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5dab12c-330b-4f25-a561-f8fb2b2d6521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 0.3995 - val_loss: 0.3461\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2908 - val_loss: 0.2432\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1955 - val_loss: 0.1489\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1076 - val_loss: 0.0687\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0452 - val_loss: 0.0353\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0335\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.0281\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0216 - val_loss: 0.0267\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0210 - val_loss: 0.0259\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0261\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0258\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0256\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0202 - val_loss: 0.0254\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0253\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0254\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.0251\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0247\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0247\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0245\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0242\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0240\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0238\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0238\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0232\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0231\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0227\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0223\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0220\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0217\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0213\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0206\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0205\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0196\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0191\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0184\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0177\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0170\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0157\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0151\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0141\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0136\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Mean Squared Error on Test Set: 0.010210011154413223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Predictions:\n",
      "[[0.3629781  0.5250806  0.7581016  0.81428784 0.8860961  0.994271  ]\n",
      " [0.09916054 0.26204312 0.38490006 0.5287611  0.6700167  0.8443483 ]\n",
      " [0.07768189 0.24224839 0.39564663 0.5626957  0.7696097  0.9529352 ]\n",
      " [0.2182804  0.40220204 0.5855825  0.67718834 0.814052   0.97043204]\n",
      " [0.07725464 0.2078698  0.33525008 0.52952474 0.70233256 0.8376509 ]\n",
      " [0.09871245 0.24276131 0.37949678 0.577079   0.74786216 0.9153534 ]\n",
      " [0.18554202 0.3351361  0.4830422  0.61240435 0.7498868  0.867164  ]\n",
      " [0.11502323 0.2705806  0.40868634 0.5749399  0.7293058  0.8937543 ]\n",
      " [0.10970011 0.27571818 0.44714206 0.62992257 0.80634624 0.9809643 ]\n",
      " [0.02972272 0.1964914  0.3060162  0.45151192 0.6199187  0.8199678 ]\n",
      " [0.09277898 0.255498   0.42393345 0.6362247  0.81007314 0.9874034 ]\n",
      " [0.17214796 0.31174445 0.46888307 0.6077052  0.7452329  0.87760997]\n",
      " [0.02133328 0.1627902  0.25062338 0.4229608  0.5969692  0.7546607 ]\n",
      " [0.28314373 0.42829427 0.61044484 0.70895004 0.80659235 0.89366746]\n",
      " [0.11646803 0.26002455 0.39796886 0.4978714  0.65162593 0.79375565]\n",
      " [0.18308632 0.34870195 0.53803414 0.6532993  0.815032   0.9561018 ]\n",
      " [0.2977707  0.44758496 0.6626092  0.74047923 0.84833646 0.95733774]\n",
      " [0.28244722 0.47660318 0.6774658  0.85784584 0.9894896  1.1084586 ]\n",
      " [0.3463725  0.5024883  0.7005316  0.802118   0.8847696  0.98791397]\n",
      " [0.17802612 0.31406483 0.44887063 0.5643119  0.6821978  0.8085706 ]\n",
      " [0.04327148 0.20674302 0.34486133 0.5562909  0.77814513 0.9380983 ]\n",
      " [0.19953543 0.3433423  0.5308085  0.67536193 0.8053904  0.9406102 ]\n",
      " [0.05692636 0.22817737 0.35446984 0.5452464  0.68789923 0.88335323]\n",
      " [0.26172772 0.45086345 0.61652505 0.7469334  0.84432834 0.9677173 ]\n",
      " [0.0961296  0.25587842 0.40497246 0.56972414 0.75792986 0.9232283 ]\n",
      " [0.07894958 0.23078224 0.33776397 0.5480415  0.7325964  0.8728518 ]\n",
      " [0.2602757  0.40604207 0.605169   0.7277222  0.8089978  0.9170042 ]\n",
      " [0.12077802 0.27911696 0.42636272 0.5686626  0.7470805  0.901873  ]\n",
      " [0.17012332 0.27425757 0.44035837 0.54268104 0.6816099  0.78347266]\n",
      " [0.276856   0.45995003 0.69750375 0.8303904  0.92356026 1.066612  ]\n",
      " [0.19487938 0.3653631  0.54825944 0.6451905  0.786698   0.9609728 ]\n",
      " [0.33292484 0.47176692 0.68309987 0.7812839  0.86649597 0.969437  ]\n",
      " [0.04120752 0.19765043 0.31263518 0.52352273 0.688709   0.86905146]\n",
      " [0.25877672 0.3774338  0.5952967  0.6625958  0.8072441  0.8984504 ]\n",
      " [0.3980075  0.5256666  0.74774814 0.76582533 0.81663036 0.8902983 ]\n",
      " [0.08704893 0.22300838 0.3131257  0.43815163 0.57184917 0.7152697 ]\n",
      " [0.28002542 0.4615939  0.6456136  0.77986825 0.92249566 1.0223838 ]\n",
      " [0.06916808 0.21666428 0.326394   0.5059708  0.6662776  0.8246017 ]\n",
      " [0.3107814  0.46345434 0.67418045 0.78753495 0.89791864 1.0058495 ]\n",
      " [0.18630253 0.37528875 0.51350963 0.65154976 0.79173344 0.94216865]\n",
      " [0.30748907 0.46241674 0.6779066  0.77558655 0.8753438  0.98080814]\n",
      " [0.18884756 0.33881712 0.50442374 0.6452256  0.7938447  0.90981054]\n",
      " [0.11877104 0.28676236 0.4300651  0.5812378  0.76185244 0.90677416]\n",
      " [0.06151356 0.23308732 0.34298787 0.54980123 0.69052774 0.87154734]\n",
      " [0.28055337 0.43683034 0.6391001  0.77493984 0.92372644 1.0172719 ]\n",
      " [0.36303267 0.5162503  0.69688344 0.7683229  0.8388116  0.9168384 ]\n",
      " [0.30732223 0.45675674 0.6595162  0.79785615 0.91435945 0.99594367]\n",
      " [0.3213783  0.45873627 0.6662675  0.7615295  0.83905643 0.94476646]\n",
      " [0.12186896 0.27050507 0.41391617 0.5843503  0.7353765  0.9067612 ]\n",
      " [0.22990796 0.38135132 0.55803204 0.73914856 0.87432826 0.98217094]\n",
      " [0.09487546 0.2244637  0.37519196 0.5202577  0.68900687 0.838627  ]\n",
      " [0.12950662 0.3026879  0.45756188 0.6218921  0.79508924 0.9493456 ]\n",
      " [0.26667395 0.46702912 0.65106684 0.7985516  0.9043935  1.0314426 ]\n",
      " [0.06988917 0.23474912 0.34888676 0.53760433 0.70521736 0.88505816]\n",
      " [0.00815486 0.17799328 0.32910383 0.5225018  0.708283   0.9261806 ]\n",
      " [0.33603254 0.4910699  0.65063107 0.75259626 0.82414365 0.90512455]\n",
      " [0.03129365 0.18012142 0.31334263 0.43204188 0.623132   0.81126446]\n",
      " [0.18967393 0.33671227 0.5184082  0.6574463  0.76891834 0.89974254]\n",
      " [0.0469011  0.17892392 0.32106513 0.48923293 0.6648182  0.82351637]\n",
      " [0.13521555 0.28011227 0.44585484 0.54362255 0.69927526 0.846673  ]]\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(5, 7)))\n",
    "model.add(Dense(6))  # Output layer with six neurons for regression\n",
    "model.compile(optimizer='adam', loss='mse')  # Mean Squared Error loss for regression\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Mean Squared Error on Test Set: {loss}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print('Predictions:')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29351c98-434d-4794-9d8b-49c2393c0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karl/anaconda3/envs/ailt00/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model_lstm_i5_7_i1_6.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailt00",
   "language": "python",
   "name": "ailt00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
